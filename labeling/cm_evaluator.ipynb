{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "sustainable-syndication",
   "metadata": {},
   "source": [
    "# Processing Titles to Evaluate CM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "impaired-cement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/merck_nl2sql/src\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%cd ~/SageMaker/merck_nl2sql/src/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "opposed-blanket",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import config\n",
    "from pipeline import nlq2SqlTool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "missing-black",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = 'Update on Clinical Aspects of Chronic Obstructive Pulmonary Disease.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "brazilian-documentary",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n"
     ]
    }
   ],
   "source": [
    "tool = nlq2SqlTool(config)\n",
    "entities = tool.detect_entities(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ranging-poetry",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TIMEDAYS': [],\n",
       " 'TIMEYEARS': [],\n",
       " 'DRUG': [],\n",
       " 'CONDITION': [{'BeginOffset': 30,\n",
       "   'EndOffset': 67,\n",
       "   'Text': 'Chronic Obstructive Pulmonary Disease',\n",
       "   'Options': [{'Description': 'Chronic obstructive pulmonary disease, unspecified',\n",
       "     'Code': 'J44.9',\n",
       "     'Score': 0.8020230531692505},\n",
       "    {'Description': 'Chronic obstructive pulmonary disease with (acute) exacerbation',\n",
       "     'Code': 'J44.1',\n",
       "     'Score': 0.7054653763771057},\n",
       "    {'Description': 'Chronic obstructive pulmonary disease with acute lower respiratory infection',\n",
       "     'Code': 'J44.0',\n",
       "     'Score': 0.6053685545921326},\n",
       "    {'Description': 'Chronic obstructive pyelonephritis',\n",
       "     'Code': 'N11.1',\n",
       "     'Score': 0.5842992067337036},\n",
       "    {'Description': 'Pulmonary heart disease, unspecified',\n",
       "     'Code': 'I27.9',\n",
       "     'Score': 0.4796171188354492}],\n",
       "   'Query-arg': 'J44.9',\n",
       "   'Placeholder': '<ARG-CONDITION><0>'}],\n",
       " 'AGE': [],\n",
       " 'STATE': [],\n",
       " 'GENDER': [],\n",
       " 'ETHNICITY': [],\n",
       " 'RACE': []}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool.process_entities(entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "structural-copyright",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "229\n"
     ]
    }
   ],
   "source": [
    "titles_path = '/home/ec2-user/SageMaker/efs/data/pilot_nl2sql_dev/cm_evaluation/selected_titles_manual.txt'\n",
    "output_path = '/home/ec2-user/SageMaker/efs/data/pilot_nl2sql_dev/cm_evaluation/selected_titles_manual_processed.txt'\n",
    "with open(titles_path, 'r') as fp:\n",
    "    titles = fp.readlines()\n",
    "    titles = [title.strip() for title in titles]\n",
    "print(len(titles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "loose-photograph",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_title(title0):\n",
    "    \"\"\"Detect entities in a given title and replace the detected ones with their concept codes.\"\"\"\n",
    "    output_title = title0\n",
    "#     print(title0)\n",
    "    detected = tool.process_entities(tool.detect_entities(title0))\n",
    "    for ent_key, ent_value in detected.items():\n",
    "        if ent_key =='DRUG' or ent_key == 'CONDITION':\n",
    "            for value in ent_value:\n",
    "                begin, end = value['BeginOffset'], value['EndOffset']\n",
    "                text = value['Text']\n",
    "                detections = value['Options']\n",
    "                outputs = []\n",
    "                for detection in detections:\n",
    "#                     print(detection)\n",
    "#                     print('+++++')\n",
    "                    outputs.append(f\"({detection['Description']}, {detection['Code']})\")\n",
    "                #print(text)\n",
    "                outputs = f'<{ent_key},' + ' / '.join(outputs) + '>'\n",
    "                output_title= output_title.replace(text, outputs)\n",
    "    output = f\"Input:\\n{title0}\\nOutput:\\n{output_title}\\n# of Correct:\\n# of Errors:\\n\"\n",
    "    return output\n",
    "\n",
    "def process_titles(titles0):\n",
    "    \"\"\"Process all titles.\"\"\"\n",
    "    print('Processing titles through CM...')\n",
    "    outputs = ''\n",
    "    for title in titles0:\n",
    "        output = process_title(title)\n",
    "        outputs += output\n",
    "    print('All titles processed successfully!')\n",
    "    return outputs\n",
    "\n",
    "def save_processed_titles(processed_titles, output_path):\n",
    "    with open(output_path, 'w') as fp:\n",
    "        fp.write(processed_titles)\n",
    "    print('Processed data saved Successfully!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "thorough-rainbow",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing titles through CM...\n",
      "All titles processed successfully!\n"
     ]
    }
   ],
   "source": [
    "#Process Titles by detecting entities and concept codes through CM\n",
    "processed_titles = process_titles(titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "dirty-bidder",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved Successfully!\n"
     ]
    }
   ],
   "source": [
    "#Save the processed data\n",
    "save_processed_titles(processed_titles, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "million-print",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_latest_p36",
   "language": "python",
   "name": "conda_pytorch_latest_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
